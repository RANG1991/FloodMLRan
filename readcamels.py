# -*- coding: utf-8 -*-
"""ReadCAMELS.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12muodiUHQ-bLMtj6NiWVO1vH7zdKxlTG
"""

import pandas as pd
import numpy as np
import netCDF4 as nc
import datetime
import geopandas as gpd

PATH_ROOT = "C:/Users/Admin/PycharmProjects/FloodMLRan/Data/CAMELS/"


def read_single_basin(station_id):
    """
    read the bounds of the required station
    """
    # Set filepath
    fn = PATH_ROOT + "/HCDN_nhru_final_671.shp"
    # Read the precipitation data file using gpd.read_file()
    basin_data = gpd.read_file(fn)
    basin = basin_data[basin_data['hru_id'] == int(station_id)]
    bounds = basin.bounds

    # get the minimum and maximum longitude and latitude
    min_lon = np.squeeze(np.floor((bounds['minx'].values * 10) / 10))
    min_lat = np.squeeze(np.floor((bounds['miny'].values * 10) / 10))
    max_lon = np.squeeze(np.ceil((bounds['maxx'].values * 10) / 10))
    max_lat = np.squeeze(np.ceil((bounds['maxy'].values * 10) / 10))

    """
    read the discharge of the required station (output)
    """
    fn = PATH_ROOT + '/Streamflow/dis_' + station_id + '.csv'
    df_dis = pd.read_csv(fn)
    df_dis.index = [datetime.datetime(df_dis['year'][i], df_dis['month'][i],
                                      df_dis['day'][i], df_dis['hour'][i],
                                      df_dis['minute'][i]) for i in range(0, len(df_dis))]
    print(df_dis)

    """
    read the precipitation of the required station (input)
    """
    # ERA5
    year_start = df_dis['year'].min() - 1
    year_end = df_dis['year'].max()
    print(year_start, year_end)
    list_of_dates = []
    list_of_total_precipitations = []
    for year in range(year_start, year_end + 1):
        print(year)
        fn = f"{PATH_ROOT}ERA5L/tp_{station_id}_{year}.nc"
        # fn = f"{PATH_ROOT}/tp_US_{2021}.nc"
        ds = nc.Dataset(fn)
        ti = ds['time'][:]
        if year == year_start:
            lon = ds['longitude'][:]
            lat = ds['latitude'][:]
            max_lon_array = lon.max()
            min_lon_array = lon.min()
            max_lat_array = lat.max()
            min_lat_array = lat.min()
            ind_lon_min = np.squeeze(np.argwhere(lon == max(min_lon, min_lon_array)))
            ind_lon_max = np.squeeze(np.argwhere(lon == min(max_lon, max_lon_array)))
            ind_lat_min = np.squeeze(np.argwhere(lat == max(min_lat, min_lat_array)))
            ind_lat_max = np.squeeze(np.argwhere(lat == min(max_lat, max_lat_array)))
        # multiply by 1000 to convert from units of meter to mm
        tp = np.asarray(ds['tp'][:, ind_lat_max:ind_lat_min + 1, ind_lon_min:ind_lon_max + 1]) * 1000
        times = [datetime.datetime.strptime("1900-01-01 00:00", "%Y-%m-%d %H:%M") + datetime.timedelta(hours=int(ti[i]))
                 for i in range(0, len(ti))]
        times = np.asarray(times)
        list_of_dates.append(times)
        list_of_total_precipitations.append(tp)

    datetimes = np.concatenate(list_of_dates, axis=0)
    precip = np.concatenate(list_of_total_precipitations, axis=0)

    print([station_id, lat[ind_lat_min], lat[ind_lat_max], lon[ind_lon_min],
           lon[ind_lon_max], precip.shape])

    # correct precip time from numpy time to datetime
    df = pd.DataFrame(data=datetimes, index=datetimes)
    datetimes = df.index.to_pydatetime()

    ls = [[precip[i, :, :]] for i in range(0, len(datetimes))]
    df = pd.DataFrame(data=ls, index=datetimes, columns=['precip'])
    # downsample the datetime data into 1D (1 day) bins and sum the values falling into the same bin
    df1 = df.resample('1D').sum()
    datetimes24 = df1.index.to_pydatetime()
    precip24 = np.stack(df1['precip'].values)

    dis = df_dis['flow'].values
    datetimesdis = df_dis.index.to_pydatetime()

    # downsample the datetime data into 1D (1 day) bins and take the mean of the values falling into the same bin
    df1 = df_dis.resample('1D').mean()
    datetimesdis24 = df1.index.to_pydatetime()
    dis24 = np.stack(df1['flow'].values)

    fn = PATH_ROOT + 'DataXY/shape_' + station_id + '.csv'
    pd.DataFrame(data=[[precip.shape[0], precip.shape[1], precip.shape[2]],
                       [precip24.shape[0], precip24.shape[1], precip24.shape[2]],
                       ],
                 columns=['time', 'lat', 'lon']).to_csv(fn, index=False)

    fn = PATH_ROOT + 'DataXY/time_' + station_id + '.npy'
    np.save(fn, datetimes)
    fn = PATH_ROOT + 'DataXY/time24_' + station_id + '.npy'
    np.save(fn, datetimes24)
    fn = PATH_ROOT + 'DataXY/precip_' + station_id
    precip.tofile(fn)
    fn = PATH_ROOT + 'DataXY/precip24_' + station_id
    precip24.tofile(fn)
    fn = PATH_ROOT + 'DataXY/timedis24_' + station_id + '.npy'
    np.save(fn, datetimesdis24)
    fn = PATH_ROOT + 'DataXY/dis24_' + station_id
    dis24.tofile(fn)
    fn = PATH_ROOT + 'DataXY/timedis_' + station_id + '.npy'
    np.save(fn, datetimesdis)
    fn = PATH_ROOT + 'DataXY/dis_' + station_id
    dis.tofile(fn)

    fn = PATH_ROOT + 'DataXY/info_' + station_id + '.txt'
    with open(fn, 'w') as f:
        print(precip.shape[0], precip.shape[1], precip.shape[2], lat[ind_lat_min], lat[ind_lat_max], lon[ind_lon_min],
              lon[ind_lon_max], file=f)

    from shapely.geometry import Point

    lonb = lon[ind_lon_min:ind_lon_max]
    latb = lat[ind_lat_max:ind_lat_min]
    lslon = [lonb[i] for i in range(0, len(lonb)) for j in range(0, len(latb))]
    lslat = [latb[j] for i in range(0, len(lonb)) for j in range(0, len(latb))]
    lat_lon_lst = []
    for i in range(0, len(lslon)):
        if np.squeeze(basin['geometry'].contains(Point(lslon[i], lslat[i]))):
            lat_lon_lst.append([lslat[i], lslon[i]])

    fn = PATH_ROOT + 'LatLon/latlon_' + station_id + '.csv'
    pd.DataFrame(data=lat_lon_lst, columns=['lat', 'lon']).to_csv(fn, index=False, float_format='%6.1f')

    fn = PATH_ROOT + 'DataXY/info_' + station_id + '.txt'
    with open(fn, 'w') as f:
        print(precip.shape[0], precip.shape[1], precip.shape[2], lat[ind_lat_min], lat[ind_lat_max], lon[ind_lon_min],
              lon[ind_lon_max], file=f)

    fn = PATH_ROOT + 'DataXY/info_' + station_id + '.txt'
    with open(fn, 'r') as f:
        s = f.read()
    info = s.split(sep=' ')
    H_LAT = int(info[1])
    W_LON = int(info[2])
    LAT_MIN = float(info[3])
    LAT_MAX = float(info[4])
    LON_MIN = float(info[5])
    LON_MAX = float(info[6])

    CNN_VIEW = 16 * np.floor((np.floor((H_LAT - 2) / 2) - 2) / 2) * np.floor((np.floor(
        (W_LON - 2) / 2) - 2) / 2)  # rule: CNN_channels_out*round((round((h-2)/2)-2)/2)*round((round((w-2)/2)-2)/2
    print(info)
    print(H_LAT, W_LON, LAT_MIN, LAT_MAX, LON_MIN, LON_MAX, CNN_VIEW)

    # CPC + ERA5
    year_start = df_dis['year'].min() - 1
    year_end = df_dis['year'].max()
    print([year_start, year_end])
    lstimec = []
    lstpc = []
    lstimee = []
    lstpe = []
    for year in range(year_start, year_end + 1):
        print(year)
        try:
            #  fn = f"{PATH_ROOT}ERA5L/tp_{station_id}_{year}.nc"
            fn = f"{PATH_ROOT}CPC/precip.{year}.nc"
            dsc = nc.Dataset(fn)
            fn = f"{PATH_ROOT}ERA5L/tp_US_{2021}.nc"
            dse = nc.Dataset(fn)
            tie = dse['time'][:]
            tic = dsc['time'][:]
            if year == year_start:
                lonc = dsc['lon'][:]
                lonc[lonc > 180] = lonc[lonc > 180] - 360
                latc = dsc['lat'][:]
                indlonminc = np.squeeze(np.argwhere(lonc <= min_lon)[-1])
                indlonmaxc = np.squeeze(np.argwhere(lonc[360:] >= max_lon)[0] + 360)
                indlatminc = np.squeeze(np.argwhere(latc <= min_lat)[0])
                indlatmaxc = np.squeeze(np.argwhere(latc >= max_lat)[-1])
                lone = dse['longitude'][:]
                late = dse['latitude'][:]
                indlonmine = np.squeeze(np.argwhere(lone <= lonc[indlonminc])[-1])
                indlonmaxe = np.squeeze(np.argwhere(lone >= lonc[indlonmaxc])[0])
                indlatmine = np.squeeze(np.argwhere(late <= latc[indlatminc])[0])
                indlatmaxe = np.squeeze(np.argwhere(late >= latc[indlatmaxc])[-1])
        except Exception as e:
            print(e)
        tpc = np.asarray(dsc['precip'][:, indlatmaxc:indlatminc, indlonminc:indlonmaxc])
        tpe = np.asarray(dse['tp'][:, indlatmaxe:indlatmine, indlonmine:indlonmaxe]) * 1000  # from units of m to mm

        timesc = [
            datetime.datetime.strptime("1900-01-01 00:00", "%Y-%m-%d %H:%M") + datetime.timedelta(hours=int(tic[i])) for
            i in range(0, len(tic))]
        timesc = np.asarray(timesc)
        lstimec.append(timesc)
        lstpc.append(tpc)
        timese = [
            datetime.datetime.strptime("1900-01-01 00:00", "%Y-%m-%d %H:%M") + datetime.timedelta(hours=int(tie[i])) for
            i in range(0, len(tie))]
        timese = np.asarray(timese)
        lstimee.append(timese)
        lstpe.append(tpe)

    cpc_datetimes = np.concatenate(lstimec, axis=0)
    cpc_precip = np.concatenate(lstpc, axis=0)
    era_datetimes = np.concatenate(lstimee, axis=0)
    era_precip = np.concatenate(lstpe, axis=0)

    ls = [[era_precip[i, :, :]] for i in range(0, len(era_datetimes))]
    df = pd.DataFrame(data=ls, index=era_datetimes, columns=['precip'])
    df1 = df.resample('1D').sum()
    era_datetimes24 = df1.index.to_pydatetime()
    era_precip24 = np.stack(df1['precip'].values)

    ls = [[cpc_precip[i, :, :]] for i in range(0, len(cpc_datetimes))]
    df = pd.DataFrame(data=ls, index=cpc_datetimes, columns=['precip'])
    cpc_datetimes24 = df.index.to_pydatetime()
    cpc_precip24 = np.stack(df['precip'].values)

    compares = np.zeros([2, len(era_datetimes24)])
    for i in range(0, len(era_datetimes24)):
        compares[0, i] = np.nanmean(era_precip24[i, :, :].flat)
        j = np.where(era_datetimes24[i] == cpc_datetimes)
        if j:
            compares[1, i] = np.nanmean(cpc_precip24[j, :, :].flat)
        else:
            compares[1, i] = np.nan

    fn = PATH_ROOT + 'DataXY/comparestime_' + station_id + '.npy'
    np.save(fn, era_datetimes24)
    fn = PATH_ROOT + 'DataXY/comp_era_cpc_' + station_id + '.npy'
    np.save(fn, compares)

    import matplotlib.pyplot as plt

    # plt.plot(era_datetimes24, compares[0,:],'b')
    # plt.plot(era_datetimes24, compares[1,:],'g')

    compares[compares < 0] = 0
    plt.plot(compares[0, :], compares[1, :], 'x')
    # plt.ylim([0,100])

    print(precip.shape)
    print([lat[ind_lat_min], lat[ind_lat_max], lon[ind_lon_min], lon[ind_lon_max]])

    # CPC
    year_start = df_dis['year'].min() - 1
    year_end = df_dis['year'].max()
    print([year_start, year_end])
    list_of_dates = []
    list_of_total_precipitations = []
    for year in range(year_start, year_end + 1):
        print(year)
        #  fn = f"{PATH_ROOT}ERA5L/tp_{station_id}_{year}.nc"
        fn = f"{PATH_ROOT}CPC/precip.{year}.nc"
        ds = nc.Dataset(fn)
        ti = ds['time'][:]
        if year == year_start:
            lon = ds['lon'][:]
            lon[lon > 180] = lon[lon > 180] - 360
            lat = ds['lat'][:]
            ind_lon_min = np.squeeze(np.argwhere(lon < min_lon)[-1])
            ind_lon_max = np.squeeze(np.argwhere(lon > max_lon)[0])
            ind_lat_min = np.squeeze(np.argwhere(lat < min_lat)[0])
            ind_lat_max = np.squeeze(np.argwhere(lat > max_lat)[-1])
            # compute
        tp = np.asarray(ds['precip'][:, ind_lat_max:ind_lat_min, ind_lon_min:ind_lon_max])
        times = [datetime.datetime.strptime("1900-01-01 00:00", "%Y-%m-%d %H:%M") + datetime.timedelta(hours=int(ti[i]))
                 for i in range(0, len(ti))]
        times = np.asarray(times)
        list_of_dates.append(times)
        list_of_total_precipitations.append(tp)

    cpc_datetimes = np.concatenate(list_of_dates, axis=0)
    cpc_precip = np.concatenate(list_of_total_precipitations, axis=0)

    from shapely.geometry import Polygon, LineString, Point

    lonc = -102.25
    latc = 43.25
    halfr = 0.5 / 2
    p1 = Polygon([(lonc - halfr, latc + halfr), (lonc + halfr, latc + halfr), (lonc + halfr, latc - halfr),
                  (lonc - halfr, latc - halfr)])
    # p1 = gpd.points_from_xy(x=[lonc-halfr,lonc+halfr,lonc+halfr,lonc-halfr,lonc-halfr], y=[latc+halfr,latc+halfr,latc-halfr,latc-halfr,latc+halfr],crs=basin.crs)
    # p1 = gpd.points_from_xy(x=[lonc-halfr,lonc+halfr,lonc+halfr,lonc-halfr,lonc-halfr], y=[latc+halfr,latc+halfr,latc-halfr,latc-halfr,latc+halfr],crs=basin.crs)
    # p1 = p1.to_crs('EPSG:4269')
    pixel = gpd.GeoSeries(p1, crs="EPSG:4269")
    # p1

    geom = basin['geometry']
    # geom.intersection(pixel)
    # geom.intersection(pixel)
    # basin['geometry'].crs
    geom.geometry

    geom[5].intersection(pixel)

    basin['geometry'].crs


def main():
    basins_stations_list = ["06452000",
                            "13340000",
                            "02315500",
                            "07226500",
                            "07068000",
                            "03164000",
                            "05585000",
                            "08164000",
                            "07292500",
                            "02231000"]
    for basin_station_id in basins_stations_list:
        read_single_basin(basin_station_id)


if __name__ == "__main__":
    main()
